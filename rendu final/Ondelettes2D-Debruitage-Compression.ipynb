{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformée en Ondelettes 2D, application au traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**BOULKAID, Yasmine**\n",
    "\n",
    "\n",
    "**IVELAND, Edda**\n",
    "  \n",
    "**4GMM TP de Signal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction: \n",
    "Le but de cet compte rendu de TP est de . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import des libraries utilisées dans ce TP\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_endpoint_url = 'https://object-rook-ceph.apps.math.cnrs.fr/'\n",
    "s3_access_key_id = '9F7EB8YBUWXDV7A4IZYW' # le contenu de secrets/dossal\n",
    "s3_secret_access_key = 'skV01Eei5M3xVOxROIDr3qymYhWtkrxPpMyj8nwb' # le contenu de secrets/dossal\n",
    "s3_bucket = 'signal-image'\n",
    "s3 = boto3.client('s3',\n",
    "                  '',\n",
    "                  endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)\n",
    "Data=[\"Lenna.jpg\",\"Canaletto.jpeg\",\"MinotaureBruite.jpeg\",\"Cartoon.jpg\"]\n",
    "if not os.path.isfile('Lenna.jpg'):\n",
    "    for filenames in Data:  \n",
    "        s3.download_file(s3_bucket,filenames,filenames)\n",
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        res=np.array(Image.open(\"Lenna.jpg\")).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        res=np.array(Image.open(\"Canaletto.jpeg\")).astype(float)\n",
    "    if name=='Minotaure':\n",
    "        res=np.array(Image.open(\"MinotaureBruite.jpeg\")).astype(float)  \n",
    "    if name=='Cartoon':\n",
    "        res=np.array(Image.open(\"Cartoon.jpg\")).astype(float) \n",
    "    return res\n",
    "options1=dict(width=400,height=400,xaxis=None,yaxis=None,toolbar=None)\n",
    "options2=dict(width=700,height=400,xaxis=None,yaxis=None,toolbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation linéaire et non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im2=chargeData('Lenna')\n",
    "im=chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size=400\n",
    "WT= pywt.wavedecn(im, 'haar', mode='per', level=2)\n",
    "arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "hv.Image(arr).opts(cmap='gray',width=size,height=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approxiamtion non linéaire en seuillant les coefficients d'ondelettes.\n",
    "On pourra utiliser les fonctions suivante : pywt.coeffs_to_array et pywt.array_to_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ApproxOnd2D(I,qmf,L,threshold):\n",
    "    Lmax=pywt.dwtn_max_level(np.shape(I),pywt.Wavelet(qmf))\n",
    "    L1=min(L,Lmax)\n",
    "    WTB= pywt.wavedecn(I, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WTB)\n",
    "    WTS=arr*(np.abs(arr)>threshold)\n",
    "    coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices)\n",
    "    Irec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    ncoeffs = len(coeffs_from_arr)\n",
    "    return Irec,ncoeffs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tester la fonction d'approximation 2D :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Irec,ncoeffs=ApproxOnd2D(im,'haar',9,50)\n",
    "pn.Row(hv.Image(im,label=\"Image originale\").opts(**options),hv.Image(Irec,label=\"Approximation non linéaire avec seuillage\").opts(**options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nous remarquons que l'image de base est la plus claire. En testant differentes valeurs de L et du seuil, nous voyons qu'en augumentant les deux valeurs, l'approximation est de moins bonne qualité. En effet, la fonction \"ApproxOnd2D\" ne garde que les coefficients d'ondelettes qui sont plus grands que le seuil. Alors quand le seuil augumente, il va y avoir moins de coefficients restants pour reconstruir l'image et donc l'image sera plus floue.**\n",
    "\n",
    "**En testant differentes bases d'ondelettes, on observe l'impact sur la résolution d'image reconstruite. Les ondelettes de Haar, étant constantes par morceaux, entraînent l'apparition de rectangles dans l'image reconstruite, contrairement aux ondelettes de Daubechies.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une focntion PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    mse = np.mean( (Iref - I) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    Val_MAX = np.max(Iref)\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test de la fonction PSNR\n",
    "PSNR(Irec,im) #pour la sortie du test du fonction ApproxOnd2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonction qui calcule le Peak Signal to Noise Ratio (PSNR), une mesure de distortion en image numérique qui permet de quantifier la qualité de reconstruction de l'image compressée par rapport à l'image originale. En général,plus le PSNR est élevé meilleure est la qualité de l'image recontruite.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approximation non linéaire en conservant un nombre N de coefficients d'ondelettes et la tester. On pourra utiliser les fonctions pywt.ravel_coeffs et unravel_coeffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ApproxOnd2nonlin(I,qmf,L,N): #Retourne Irec et p le PSNR\n",
    "    N1=np.shape(I)[0]\n",
    "    N2=np.shape(I)[1]\n",
    "    Lmax=pywt.dwtn_max_level(np.shape(I),pywt.Wavelet(qmf))\n",
    "    L1=min(L,Lmax)\n",
    "    WT= pywt.wavedecn(I, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices,coeff_shapes = pywt.ravel_coeffs(WT)\n",
    "    Ind=np.argsort(np.abs(arr))\n",
    "    WTS=np.zeros_like(arr)\n",
    "    WTS[Ind[N1*N2-N:N1*N2]]=arr[Ind[N1*N2-N:N1*N2]]\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices,coeff_shapes)\n",
    "    Irec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    p=PSNR(Irec,I)\n",
    "    return Irec,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Irec,p=ApproxOnd2nonlin(im2,'db2',6,5000)\n",
    "pn.Row(hv.Image(im2,label=\"Image originale\").opts(**options),hv.Image(Irec,label=\"Image reconstruit par approximation non linéaire de N coefficients\").opts(**options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ici, plutôt que de restreindre le nombre de coefficients d'ondelettes par un seuil, nous le définissons directement avec N. Cette approche entraîne également une grande dégradation de la qualité de l'image.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un Dashboard qui permet d'explorer la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3','sym2','sym3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Approx2D(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,7))\n",
    "    N = param.Integer(2000,bounds=(1,10000))\n",
    "  #  @param.depends('wave', 'N', 'L')\n",
    "    def view(self):\n",
    "        im = imagesRef[self.image]\n",
    "        Irec,p = ApproxOnd2nonlin(im,self.wave,self.L,self.N)\n",
    "        return pn.Column(pn.Row(hv.Image(im,label = \"Image originale\").opts(**options),hv.Image(Irec, label = \"Image reconstruit\").opts(**options),\"PSNR :\",p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "approx2D = Approx2D()\n",
    "pn.Row(approx2D.param,approx2D.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L'analyse de nos résultats révèle plusieurs observations importantes.** <br>\n",
    "**- Tout d'abord, nous constatons qu'une augmentation du nombre N de coefficients d'ondelettes conservés se traduit par une amélioration du PSNR et donc une meilleure qualité d'image reconstruite.** <br>\n",
    "**- Nous notons que les ondelettes de Haar présentent un PSNR inférieur à celui des ondelettes de Daubechies ou de Coifman. Cette différence peut être attribuée à leur nature constante par morceaux, qui les rend moins adaptées aux caractéristiques des images étudiées.** <br> \n",
    "**- En outre, il est intéressant de souligner que l'élévation de la profondeur de la transformation en ondelettes L conduit à une augmentation du PSNR, et par conséquent à une meilleure qualité d'image reconstruite.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'experiences qui permet d'explorer la fonction ApproxOnd2nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences = {'Image':imagesRef,'N':np.linspace(1000,50000,30),'wave':wavelist}\n",
    "dfexp = pd.DataFrame(list(itertools.product(*experiences.values())),columns=experiences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la fonction qui à une ligne de la base de donnée précédente calcule le PSNR associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitPSNR(I,qmf,N): #,sigma,T):\n",
    "    seednoise=np.arange(N)\n",
    "    N1=len(I.flatten())\n",
    "    Lmax=pywt.dwt_max_level(len(I),pywt.Wavelet(qmf).dec_len)\n",
    "    Seuil=10 #T*sigma\n",
    "    psnr1=np.zeros(N)\n",
    "    for k in seednoise:\n",
    "        np.random.seed(seed=seednoise)\n",
    "        bruit=np.random.normal(0,1,(N1,N1))\n",
    "        IB=I+sigma*bruit\n",
    "        Irec=SeuillageOndelette(IB,qmf,Lmax,Seuil)\n",
    "        psnr1[k]=psnr(I,Irec)\n",
    "    return np.mean(psnr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row2PSNR(row):\n",
    "    Lmax = pywt.dwt_max_level(len(imagesRef[row.Image]),pywt.Wavelet(row.wave).dec_len)\n",
    "    Irec,p=ApproxOnd2nonlin(imagesRef[row.Image],row.wave,Lmax,int(row.N))\n",
    "    return {'PSNR':p}\n",
    "   # p=DebruitPSNR(imagesRef[im],row.wave,row.N) #,row.sigma,row.Th) l'ancien version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la fonction sur la base de donnée et ajouter la colonne PSNR à la base de données dfexp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = dfexp.apply(row2PSNR,axis=1)\n",
    "dfexp[['PSNR']] = pd.DataFrame.from_records(result.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "h = HoverTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dfexp.hvplot('N','PSNR',by='wave',kind='scatter',groupby=['Image']).opts(width=600,tools = [h]).redim.range(PSNR=(22,55))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour l'image Lenna, nous observons que l'ondelette de Coifman 3 (en jaune) fonctionne le mieux, ce qui se traduit par un PSNR plus élevé. Les mêmes résultats sont observés pour l'image Canaletto. Egalement, lorsque le nombre N de coefficients d'ondelettes augmente, la qualité de l'image approximée augmente également, ce qui est cohérent avec nos observations précédentes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue un seuillage dur en ondelettes et la tester. On pourra utiliser la fonction pywt.ravel_coeffs et on pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SeuillageDurOndelettes(I,qmf,L,Seuil):\n",
    "    WTB= pywt.wavedecn(I, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "    WTS=arr*(np.abs(arr)>Seuil)\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices, coeff_shapes)\n",
    "    Irec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    return Irec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dashboard qui permet d'explorer la fonction SeuillageDurOndelettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WaveSeuillage(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(10,bounds=(1,1000))\n",
    "    def view(self):\n",
    "        im = imagesRef[self.image]\n",
    "        Irec = SeuillageDurOndelettes(im,self.wave,self.L,self.Seuil)\n",
    "        p = PSNR(im,Irec)\n",
    "        return pn.Column(pn.Row(hv.Image(im, label = \"Image originale\").opts(**options),hv.Image(Irec, label = \"Image Reconstruit\").opts(**options)),\"PSNR\",p) #hv.Image(im).opts(**options)*hv.Image(Irec).opts(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage du dashboard\n",
    "Wavethresholding = WaveSeuillage()\n",
    "pn.Row(Wavethresholding.param,Wavethresholding.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quand le seuil augumente, l'image recontruite devient plus en plus dégradée. Cela est due au fait qu'on ne garde que les coefficients d'ondelettes plus grands que ce seuil. Nous remarquons que L n'a pas trop d'impact quand la valeur du seuil est petit. Quand on augumente le seuil et L à la fois, l'image est plus lisible que lorsque L est petit. Aussi, la valeur du PSNR est plus petite pour les ondelettes de Haar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bruitage de l'image\n",
    "n1,n2=np.shape(im)\n",
    "B=np.random.randn(n1,n2)\n",
    "sigma=10\n",
    "ib=im+sigma*B\n",
    "ib=np.clip(ib,0,255)\n",
    "hv.Image(ib).opts(cmap='gray',width=400,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire un dashboard qui permet de visualiser rapidement l'effet d'un débruitage en ondelettes et qui renvoie les images originales, bruitées et débruitées ainsi que les PSNR associés aux images bruitéeset débruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Debruit(I,qmf,seednoise,sigma,T, L):\n",
    "    N1=len(I)\n",
    "    np.random.seed(seed=seednoise)\n",
    "    bruit=np.random.normal(0,1,(N1,N1))\n",
    "    Lmax=pywt.dwt_max_level(len(I),pywt.Wavelet(qmf).dec_len)\n",
    "    IB=I+sigma*bruit\n",
    "    Seuil=T*sigma\n",
    "    Irec=SeuillageDurOndelettes(IB,qmf,L,Seuil)\n",
    "    p1=PSNR(I,IB)\n",
    "    p2=PSNR(I,Irec)\n",
    "    return Irec,IB,p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WaveDebruit(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self):\n",
    "        im = imagesRef[self.image]\n",
    "        Irec,IB,p1,p2 = Debruit(im,self.wave,self.seednoise,self.Sigma, self.Seuil, self.L)\n",
    "        return pn.Column(pn.Row(hv.Image(im, label = \"Image originale\").opts(**options),hv.Image(IB,label = \"Image bruitée\").opts(**options),hv.Image(Irec,label = \"Image débruitée\").opts(**options)),\"PSNR entre l'image bruitée et l'image originale: \", p1,\"#PSNR entre l'image reconstruite et l'image originale : \", p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wavedebruit = WaveDebruit()\n",
    "pn.Row(wavedebruit.param,wavedebruit.view)\n",
    "#il faut verifier le gain en pnsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le PSNR est plus élevée entre l'image reconstruite et l'image originale. Il est de meilleure qualité que celui d'image bruitée. Nous observons les même tendances que la partie précedente, à savoir quand le seuil augumente, la qualité de l'image baisse.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images et translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise un débruitage avec une moyenne sur des NbT fois NbT translations et la tester. Vérifier le gain en PNSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DebruitTranslation(IB,wave,seuil,NbT):\n",
    "    Lmax=pywt.dwt_max_level(len(IB),pywt.Wavelet(wave).dec_len)\n",
    "    ISum=0*IB\n",
    "    P=np.zeros((NbT,NbT))\n",
    "    rounds = 0\n",
    "    for k in np.arange(0,NbT):\n",
    "        for i in np.arange(0,NbT):\n",
    "            rounds +=1\n",
    "            IBtemp=np.roll(IB,(k, i),axis = (0,1))\n",
    "            Irectemp=SeuillageDurOndelettes(IBtemp,wave,Lmax,seuil)\n",
    "            Irectemp2=np.roll(Irectemp,(-k, -i),axis = (0,1))\n",
    "            ISum += Irectemp2\n",
    "            Irec=ISum/rounds\n",
    "    P=PSNR(IB,Irec)\n",
    "    return Irec,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n1,n2=np.shape(im2)\n",
    "sigma = 25\n",
    "br=np.random.randn(n1,n2) #On tire aleatoirement le bruit\n",
    "IB=im2+sigma*br\n",
    "Irec, P = DebruitTranslation(IB,'db2',seuil=30,NbT=10)\n",
    "P2 = PSNR(IB,im2)\n",
    "P3 = PSNR(Irec,im2)\n",
    "print(Irec.shape)\n",
    "pn.Column(pn.Row(hv.Image(IB,label=\"Image bruitée\").opts(**options),\n",
    "       hv.Image(Irec,label=\"Image débruitée\").opts(**options)),#\"PSNR entre l'image bruitée et l'image recontruite: \",P ,\n",
    "          \"PSNR entre l'image originale et l'image bruitée: \", P2,\n",
    "          \"PSNR entre l'image originale et l'image reconstruite: \",P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dasboard pour explorer la fonction précédente. La sortie doit aussi être composée de 3 images et 2 PSNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter porquoi 3*sigma est la valeur optimal du seuil. \n",
    "\n",
    "**Le produit scalaire $<x+ae, \\psi> = <x,\\psi> + <ae,\\psi>$. Et $<ae,\\psi>$ suit une loi normale de paramètres $(0,\\sigma^2)$. Donc on sait que le bon seuil est de 3 écart-types i.e. $3 \\sigma$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Debruit_translat(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    NbT = param.Integer(2,bounds=(1,8))\n",
    "    Sigma = param.Number(10,bounds=(1,30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    def view(self): \n",
    "        im = imagesRef[self.image] \n",
    "        N1 = len(im)\n",
    "        np.random.seed(seed=self.seednoise)\n",
    "        bruit=np.random.normal(0,1,(N1,N1))\n",
    "        IB = im + self.Sigma*bruit\n",
    "        Irec, p = DebruitTranslation(IB,self.wave,3*self.Sigma,self.NbT)\n",
    "        p1=PSNR(IB,im) #PSNR(I,Iref)\n",
    "        p2=PSNR(Irec,im)\n",
    "        return pn.Column(pn.Row(hv.Image(im).opts(**options),hv.Image(Irec).opts(**options),hv.Image(IB).opts(**options)),\"PSNR entre l'image originale et l'image bruitée\",p1,\"PSNR entre l'image originale et l'image debruitée\",p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "debruit_trans = Debruit_translat()\n",
    "pn.Row(debruit_trans.param,debruit_trans.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comme nous avons vu en cours, la qualité de reconstruction est meilleure quand on rajoute des translations. Nous le voyons parce que quand le nombre de translations NbT augume, le gain en PSNR augumente aussi.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'une image couleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer le débruitage d'une image générale, c'est à dire d'une image couleur dont le format n'est pas carré et dont les dimensions ne sont pas des puissnaces de 2 on procède comme suit :\n",
    "\n",
    "1) On effectue un débruitage séparé sur chacun des canaux.\n",
    "\n",
    "2) Le format carré n'est pas un vrai problème, il faut juste que les dimensions soit des multiples de puissances de \n",
    "2. C'est la puissance de 2 qui définira l'échalle maximale de la décomposition en ondelettes. Il est donc préférable que les dimensions de l'images soient un petit multiple d'une puissance de 2.\n",
    "\n",
    "3) On étend l'image par symétrie ou périodicité pour qu'elle ait les dimensions souhaitées. A la fin du processus de débruitage on tronque le résultat obtenu à la dimension de l'image originale.\n",
    "\n",
    "4) Si le niveau de bruit n'est pas connu, il faut l'estimer en utilisant les coefficients d'ondelettes de la plus petite échelle (voir le notebook sur le débruitage de signaux).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposer une fonction qui effectue le débruitage d'une image couleur de dimensions quelconques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction peut prendre en entrée un tableau numpy ou une image dans une format d'images classique.\n",
    "Vous pouvez tester votre programme en bruitant vous même une ou plusieurs images de référence et évaluer le gain en terme de PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def symetrize_image(image, desired_shape):\n",
    "    \n",
    "    sym_image = np.zeros(desired_shape)\n",
    "    sym_image[:image.shape[0], :image.shape[1], :] = image\n",
    "    # Symmetrize along rows\n",
    "    for i in range(image.shape[0], desired_shape[0]):\n",
    "        sym_image[i, :, :] = sym_image[2 * image.shape[0] - i - 1, :, :]\n",
    "    # Symmetrize along columns\n",
    "    for j in range(image.shape[1], desired_shape[1]):\n",
    "        sym_image[:, j, :] = sym_image[:, 2 * image.shape[1] - j - 1, :]\n",
    "    return sym_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PSNR_Couleur (I,Iref):\n",
    "    n1,n2,n3 = np.shape(I)\n",
    "    mse = np.mean((Iref-I)**2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    VALMAX = np.max(Iref)\n",
    "    mse=(1/n1*n2*n3)*np.sum((I-Iref)**2)\n",
    "    return 20*np.log10(VALMAX**2/np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Debruitage_image_couleur(image, qmf, seednoise, sigma, T, L, NbT):\n",
    "    Seuil=T*sigma\n",
    "    np.random.seed(seed=seednoise)\n",
    "    noise = np.random.normal(0, 1, image.shape)\n",
    "    noisy_image = image + sigma * noise\n",
    "    \n",
    "    # Symmetrize image to match desired shape\n",
    "    desired_shape = (image.shape[0] + image.shape[0] % 2, image.shape[1] + image.shape[1] % 2, 3)\n",
    "    noisy_image = symetrize_image(noisy_image, desired_shape)\n",
    "    ISum=np.zeros(np.shape(image))\n",
    "    Irec=np.zeros(np.shape(image))\n",
    "    denoised_channels = []\n",
    "    for channel in range(3):\n",
    "        channel_image = noisy_image[:,:, channel]\n",
    "        for i in np.arange(0,NbT):\n",
    "            IBtemp=np.roll(channel_image,i,axis = 1)\n",
    "            IBtemp=np.roll(IBtemp,i,axis = 0)\n",
    "            denoised_channel = SeuillageDurOndelettes(IBtemp,qmf,L,Seuil)\n",
    "            #denoised_channels.append(denoised_channel)\n",
    "            denoised_channel2=np.roll(denoised_channel,-i,axis = 1)\n",
    "            denoised_channel2=np.roll(denoised_channel2,-i,axis = 0)\n",
    "            ISum[:,:,channel]=ISum[:,:,channel]+denoised_channel2\n",
    "            Irec[:,:,channel]=ISum[:,:,channel]/(i+1)\n",
    "    # Reconstruct denoised image\n",
    "   # Irec = np.stack(denoised_channels, axis=-1)\n",
    "    \n",
    "    # Compute PSNR\n",
    "    psnr1 = PSNR_Couleur(image, noisy_image)\n",
    "    psnr2 = PSNR_Couleur(image, Irec)\n",
    "    \n",
    "    return Irec, noisy_image, psnr1, psnr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ca = chargeData('Cartoon')\n",
    "Mi = chargeData('Minotaure')\n",
    "imagesRef2 = {\"Cartoon\" : Ca ,\"Minotaure\" : Mi}\n",
    "pn.Row(hv.Raster(imagesRef2[\"Cartoon\"]).opts(**options2),hv.Raster(imagesRef2[\"Minotaure\"]).opts(**options2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test du fonction\n",
    "# Paramètres pour le bruitage et le débruitage\n",
    "image_reference = chargeData(\"Cartoon\")\n",
    "qmf = 'db1'  # Choix de l'ondelette\n",
    "seednoise = 42  # Graine pour la génération du bruit\n",
    "sigma = 20  # Écart-type du bruit gaussien\n",
    "T = 2  # Facteur de seuil pour le seuillage des coefficients d'ondelettes\n",
    "L = 3  # Niveau maximal de décomposition en ondelettes\n",
    "NbT = 5\n",
    "# Débruitage de l'image bruitée\n",
    "image_denoised, noisy_image, psnr1, psnr2 = Debruitage_image_couleur(image_reference, qmf, seednoise, sigma, T, L,NbT)\n",
    "\n",
    "# Affichage des images et des valeurs de PSNR\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image_reference.astype('uint8'))\n",
    "plt.title('Image de référence')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noisy_image.astype('uint8'))\n",
    "plt.title(f'Image bruitée\\nPSNR: {psnr1:.2f} dB')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(image_denoised.astype('uint8'))\n",
    "plt.title(f'Image débruitée\\nPSNR: {psnr2:.2f} dB')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer les méthodes par seuillage dans une base d'ondelettes en effectuant un seuillage par blocs. C'est à dire, ne pas décider de conserver ou pas un coefficients en fonction de sa seule amplitude mais plutôt en fonction de l'énergie d'un voisinage de coefficients. \n",
    "\n",
    "Voir : http://www.cnrs.fr/insmi/spip.php?article265\n",
    "\n",
    "En effet, il est rare qu'un coefficient soit significatif seul au milieu de coefficients nuls. \n",
    "\n",
    "La mméthode de sueillage par blocs consiste à choisir une taille de voisinage (par exemple 4*4 coeffients en dimension 2) pour une échelle et une direction donnée et de conserver l'intégralité des coefficients si l'énergie (la somme des carrés des coefficients) est supérieure à un seuil et de les mettre tous à 0 si ce n'est pas le cas. \n",
    "\n",
    "Dans ce cas aussi, les translations permettent d'améliorer le rendu visuel en limitant les effets de blocs.\n",
    "\n",
    "On peut aussi constuire des blocs \"3D\" en considérant des blocs qui comprennent les coefficients des 3 créneaux de couleurs. L'idée est de corréler le débruitage un peu à travers l'espace et l'espace des couleurs.\n",
    "\n",
    "Il est possible d'effectuer un débruitage en changeant d'espace colorimétrique en passant du RGB au YUV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruiter un minotaure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de tout ce qui a été fait précédemment, proposer une version débruitée de l'image couleur contenue dans le tableau Mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Minotaure=np.clip(Mi,0,255)\n",
    "hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Debruitage_image_couleur_b(image, qmf, sigma, T, L, NbT):\n",
    "    Seuil=T*sigma\n",
    "    \n",
    "    # Symmetrize image to match desired shape\n",
    "    desired_shape = (image.shape[0] + image.shape[0] % 2, image.shape[1] + image.shape[1] % 2, 3)\n",
    "    image = symetrize_image(image, desired_shape)\n",
    "    ISum=np.zeros(np.shape(image))\n",
    "    Irec=np.zeros(np.shape(image))\n",
    "    denoised_channels = []\n",
    "    for channel in range(3):\n",
    "        channel_image = image[:,:, channel]\n",
    "        for i in np.arange(0,NbT):\n",
    "            IBtemp=np.roll(channel_image,i,axis = 1)\n",
    "            IBtemp=np.roll(IBtemp,i,axis = 0)\n",
    "            denoised_channel = SeuillageDurOndelettes(IBtemp,qmf,L,Seuil)\n",
    "            #denoised_channels.append(denoised_channel)\n",
    "            denoised_channel2=np.roll(denoised_channel,-i,axis = 1)\n",
    "            denoised_channel2=np.roll(denoised_channel2,-i,axis = 0)\n",
    "            ISum[:,:,channel]=ISum[:,:,channel]+denoised_channel2\n",
    "            Irec[:,:,channel]=ISum[:,:,channel]/(i+1)\n",
    "    # Reconstruct denoised image\n",
    "   # Irec = np.stack(denoised_channels, axis=-1)\n",
    "    \n",
    "    psnr2 = PSNR_Couleur(image, Irec)\n",
    "    \n",
    "    return Irec, psnr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Debruit_translat_Minotaure(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"db2\",objects=wavelist)\n",
    "    NbT = param.Integer(4,bounds=(1,8))\n",
    "    Sigma = param.Number(10,bounds=(1,100))\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    T=param.Number(3,bounds=(0,8))\n",
    "    def view(self):\n",
    "        #S = Mi\n",
    "        #Minotaure=np.clip(Mi,0,255)\n",
    "\n",
    "        #Débruitage :\n",
    "        Irec, p = Debruitage_image_couleur_b(Mi,self.wave,self.L,self.T,self.Sigma,self.NbT)\n",
    "        #MinotaureRec=np.clip(Irec,0,255)\n",
    "\n",
    "        Ibr = hv.RGB(Minotaure.astype('uint8'),label=\"Image bruitée originale\").opts(xlabel=None,ylabel=None,width=350,height=350)\n",
    "        Ideb = hv.RGB(Irec.astype('uint8'),label = \"Image débruitée\").opts(xlabel=None,ylabel=None,width=350,height=350)\n",
    "\n",
    "        return pn.Column(pn.Row(Ibr,Ideb),\"PSNR entre l'image bruitée originale et l'image debruitée\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DebruitTranslatMinotaure = Debruit_translat_Minotaure()\n",
    "pn.Row(DebruitTranslatMinotaure.param,DebruitTranslatMinotaure.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédiger également une fonction prenant en entrée un nom de fichier \n",
    "permettant de calculer le PSNR de votre proposition d'image débruitée avec l'image en question.\n",
    "On calcule le PSNR entre deux images couleurs en calculant la somme des erreurs quadratiques sur les 3 canaux.\n",
    "\n",
    "Attention, l'image a 3 canaux de couleur, n'est pas carrée et les dimensions ne sont pas des puissances de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'expériences pour évaluer l'impact des translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour explorer les performances de l'invariance par translation pour le débruitage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiences_DebruitTrans = {'Image':imagesRef,'NbT':np.arange(1,5),'wave':wavelist,'Sigma':np.linspace(10,30,2)}\n",
    "dfexp_DebruitTrans = pd.DataFrame(list(itertools.product(*experiences_DebruitTrans.values())),columns=experiences_DebruitTrans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui calcule le PSNR moyen sur n réalisations de bruit du débruitage d'une image avec NbT*NbT translations (qui utilise par exemple la fonction DebruitTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Debruit_Translat_PSNRMoyen(I,wave,sigma,NbT,n):\n",
    "    P2=0\n",
    "  #  I=np.clip(I,0,255)\n",
    "    n1,n2 = I.shape\n",
    "    for i in np.arange(0,n):\n",
    "        np.random.seed(seed=20)\n",
    "        noise = np.random.normal(0, 1, (n1,n2))\n",
    "        #noise = np.random.randn(n1,n2)\n",
    "        IB= I +sigma*noise\n",
    "       # IB=np.clip(IB,0,255)\n",
    "        Irec,P = DebruitTranslation(IB,wave,3*sigma,NbT)\n",
    "        #Irec=np.clip(Irec,0,255)\n",
    "        P2 += PSNR(Irec,I)\n",
    "    return P2/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire la fonction qui à une ligne de la base de données précédente calcule le PSNR moyen sur 4 réalisations du bruit. Puis l'appliquer à la base de données et ajouter la colonne des PSNR calculés à la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row2DebruitTrans(row):\n",
    "    Pmoy=Debruit_Translat_PSNRMoyen(imagesRef[row.Image],row.wave,row.Sigma,row.NbT,4)\n",
    "    return {'PSNR':Pmoy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2 = dfexp_DebruitTrans.apply(row2DebruitTrans,axis=1)\n",
    "dfexp_DebruitTrans[['PSNR']] = pd.DataFrame.from_records(result2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser les résulatst contenus dans la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_DebruitTrans.hvplot('NbT','PSNR',by='wave',kind='scatter',groupby=['Sigma','Image']).opts(width=600,tools = [h]).redim.range(PSNR=(0,55),NbT=(0.5,4.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification et Entropie de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShannonEntropy(x):\n",
    "    value,counts = np.unique(x, return_counts=True)\n",
    "    Proba=counts/len(x)\n",
    "    Ent=-np.sum(np.log2(Proba)*Proba)\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([13,13,2,7,13,7,1,13])\n",
    "print(ShannonEntropy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([-2,-3,1,0,1,0,-2,-3])\n",
    "print(ShannonEntropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue la quantification de la transformée en ondelettes avec un pas \"Pas\". On pourra à nouveau utiliser la commande pywt.ravel_coeffs. La fonction doit renvoyer l'image calculée par quantification, le PSNR associé ainsi que le nombre d'octets estimé par la valeur de l'entropie a priori nécessaire pour coder une telle image. On considérera qu'on code séparément les coefficients d'échelle et les coefficients d'ondelettes. Tester la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def QuantificationOndelettes(I,qmf,Pas):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le dashboard asscoié à la fonction précédente. \n",
    "Le dashboard doit renvoyer l'image quantifiée, le PSNR de l'image ainsi que le facteur de compression théorique associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveQuant(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    QS = param.Number(30,bounds=(10,300))\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour comparer les différentes ondelettes pour la quantification... et poursuivre jusqu'à obtenir un affichage de la base de données ainsi créée avec hvplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences_quant = {'QS':np.linspace(30,200,10),'wave':wavelist}\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DistorsionRate(row):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons ici d'effectuer la compression sur les 3 canau RGB. Or l'oeil humain est plus sensible à la luminance qu'aux composantes purement chromatiques. C'est pourquoi, la plupart des algorithmes de compressions sont effectué dans un espace colorimétrique YUV où Y est la luminance. On alloue alors plus d'information au canal Y et on comprime plus drastiquement les deux autres canaux. Une méthode standart consiste par exemple à sous-échantionner d'un facteur 2 les deux composantes U et V avant de les comprimer. \n",
    "\n",
    "https://fr.wikipedia.org/wiki/Sous-échantillonnage_de_la_chrominance\n",
    "\n",
    "On obtient alors des images de chrominances moins résolues et donc moins lourdes mais le rendu final reste correct car l'oeil humain est nettement plus sensible à la luminance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def symetrize_image(image, desired_shape):\n",
    "    \"\"\"\n",
    "    Extend image by symmetrization to match desired_shape.\n",
    "    \"\"\"\n",
    "    sym_image = np.zeros(desired_shape)\n",
    "    sym_image[:image.shape[0], :image.shape[1], :] = image\n",
    "    # Symmetrize along rows\n",
    "    for i in range(image.shape[0], desired_shape[0]):\n",
    "        sym_image[i, :, :] = sym_image[2 * image.shape[0] - i - 1, :, :]\n",
    "    # Symmetrize along columns\n",
    "    for j in range(image.shape[1], desired_shape[1]):\n",
    "        sym_image[:, j, :] = sym_image[:, 2 * image.shape[1] - j - 1, :]\n",
    "    return sym_image\n",
    "\n",
    "def Debruitage_image_couleur(image, qmf, seednoise, sigma, T, L):\n",
    "    \"\"\"\n",
    "    Perform denoising on a color image using wavelet thresholding.\n",
    "    \n",
    "    Arguments:\n",
    "    image : numpy array\n",
    "        Input color image.\n",
    "    qmf : str\n",
    "        Name of the orthogonal wavelet to use.\n",
    "    seednoise : int\n",
    "        Seed for the random number generator for noise generation.\n",
    "    sigma : float\n",
    "        Standard deviation of the Gaussian noise.\n",
    "    T : float\n",
    "        Threshold factor for wavelet coefficient thresholding.\n",
    "    L : int\n",
    "        Maximum level of wavelet decomposition.\n",
    "    \n",
    "    Returns:\n",
    "    Irec : numpy array\n",
    "        Denoised image.\n",
    "    IB : numpy array\n",
    "        Noisy image.\n",
    "    psnr1 : float\n",
    "        Peak Signal-to-Noise Ratio (PSNR) between the noisy and original image.\n",
    "    psnr2 : float\n",
    "        Peak Signal-to-Noise Ratio (PSNR) between the denoised and original image.\n",
    "    \"\"\"\n",
    "    N1, N2, _ = image.shape\n",
    "    np.random.seed(seed=seednoise)\n",
    "    noise = np.random.normal(0, 1, (N1, N2, 3))\n",
    "    noisy_image = image + sigma * noise\n",
    "    \n",
    "    # Symmetrize image to match desired shape\n",
    "    desired_shape = (N1 + N1 % 2, N2 + N2 % 2, 3)\n",
    "    noisy_image = symetrize_image(noisy_image, desired_shape)\n",
    "    \n",
    "    # Wavelet denoising separately on each channel\n",
    "    denoised_channels = []\n",
    "    for channel in range(3):\n",
    "        channel_image = noisy_image[:, :, channel]\n",
    "        coeffs = pywt.wavedec2(channel_image, qmf, mode='symmetric', level=L)\n",
    "        denoised_coeffs = list(map(lambda x: pywt.threshold(x, T * sigma, mode='soft'), coeffs))\n",
    "        denoised_channel = pywt.waverec2(denoised_coeffs, qmf, mode='symmetric')[:N1, :N2]\n",
    "        denoised_channels.append(denoised_channel)\n",
    "    \n",
    "    # Reconstruct denoised image\n",
    "    Irec = np.stack(denoised_channels, axis=-1)\n",
    "    \n",
    "    # Compute PSNR\n",
    "    psnr1 = PSNR(image, noisy_image)\n",
    "    psnr2 = PSNR(image, Irec)\n",
    "    \n",
    "    return Irec, noisy_image, psnr1, psnr2\n",
    "\n",
    "#def PSNR(original, noisy):\n",
    "    \"\"\"\n",
    "    Compute Peak Signal-to-Noise Ratio (PSNR) between original and noisy images.\n",
    "    \"\"\"\n",
    "   # mse = np.mean((original - noisy) ** 2)\n",
    "   # if mse == 0:\n",
    "   #     return float('inf')\n",
    "   # max_pixel = 255.0\n",
    "   # psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "   # return psnr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
